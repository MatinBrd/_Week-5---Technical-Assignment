{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5f832bb4",
      "metadata": {
        "id": "5f832bb4"
      },
      "source": [
        "# Week 5 - Technical Assignment: Fine Tuning using LoRA and PEFT\n",
        "This notebook covers the fine-tuning of an instruction-following LLM using LoRA and PEFT techniques. We will go through all the required steps, from loading the model to uploading it to Hugging Face."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64c1a207",
      "metadata": {
        "id": "64c1a207"
      },
      "source": [
        "## 1. Install Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eec2236d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eec2236d",
        "outputId": "808d9cc8-6e9c-4587-bed9-79b358fc8dee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.3.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.45.2-py3-none-manylinux_2_24_x86_64.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.5.1+cu124)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Downloading datasets-3.3.1-py3-none-any.whl (484 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m484.9/484.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.45.2-py3-none-manylinux_2_24_x86_64.whl (69.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, datasets, bitsandbytes\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed bitsandbytes-0.45.2 datasets-3.3.1 dill-0.3.8 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 xxhash-3.5.0\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install transformers datasets peft bitsandbytes accelerate huggingface_hub\n",
        "!pip install sentencepiece  # Required for certain models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bea7ffa",
      "metadata": {
        "id": "3bea7ffa"
      },
      "source": [
        "## 2. Load the Dataset from Hugging Face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c6207eb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c6207eb",
        "outputId": "49fb62b2-0d5a-4623-f77b-ba00000d50fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.', 'label': 0}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load a sample dataset from Hugging Face\n",
        "dataset = load_dataset(\"imdb\", split=\"train[:1%]\")\n",
        "print(dataset[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6eb8ce0",
      "metadata": {
        "id": "c6eb8ce0"
      },
      "source": [
        "## 3. Create Bitsandbytes Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac6ca962",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac6ca962",
        "outputId": "a7d9d1d3-e682-4e17-a6a4-538ed6534d52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:bitsandbytes.cextension:Could not load bitsandbytes native library: /lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.32' not found (required by /usr/local/lib/python3.11/dist-packages/bitsandbytes/libbitsandbytes_cpu.so)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/bitsandbytes/cextension.py\", line 85, in <module>\n",
            "    lib = get_native_library()\n",
            "          ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/bitsandbytes/cextension.py\", line 72, in get_native_library\n",
            "    dll = ct.cdll.LoadLibrary(str(binary_path))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/ctypes/__init__.py\", line 454, in LoadLibrary\n",
            "    return self._dlltype(name)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/ctypes/__init__.py\", line 376, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "OSError: /lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.32' not found (required by /usr/local/lib/python3.11/dist-packages/bitsandbytes/libbitsandbytes_cpu.so)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bitsandbytes loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import bitsandbytes as bnb\n",
        "\n",
        "# No specific configuration needed for basic quantization in this example\n",
        "print(\"Bitsandbytes loaded successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "duCiC22pOAA6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duCiC22pOAA6",
        "outputId": "12ba3d51-9950-4eab-b60a-d1f24ef6eb52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "avWIHbi-O6M6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avWIHbi-O6M6",
        "outputId": "59722759-7554-48a0-ea11-3de539a6004f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: bitsandbytes 0.45.2\n",
            "Uninstalling bitsandbytes-0.45.2:\n",
            "  Successfully uninstalled bitsandbytes-0.45.2\n",
            "Collecting bitsandbytes\n",
            "  Using cached bitsandbytes-0.45.2-py3-none-manylinux_2_24_x86_64.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.5.1+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
            "Using cached bitsandbytes-0.45.2-py3-none-manylinux_2_24_x86_64.whl (69.7 MB)\n",
            "Installing collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.45.2\n",
            "Collecting bitsandbytes-cuda117\n",
            "  Using cached bitsandbytes_cuda117-0.26.0.post2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Using cached bitsandbytes_cuda117-0.26.0.post2-py3-none-any.whl (4.3 MB)\n",
            "Installing collected packages: bitsandbytes-cuda117\n",
            "Successfully installed bitsandbytes-cuda117-0.26.0.post2\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y bitsandbytes\n",
        "!pip install -U bitsandbytes\n",
        "!pip install bitsandbytes-cuda117"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oe3_c3ulPDWM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "oe3_c3ulPDWM",
        "outputId": "fc4845d8-f71c-4856-9eda-28ae27fc4d77"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "libcudart.so.11.0: cannot open shared object file: No such file or directory",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-1f60046bdb0d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mbitsandbytes\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbnb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CUDA available:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/bitsandbytes/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# This source code is licensed under the MIT license found in the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# LICENSE file in the root directory of this source tree.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'='\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m30\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'WARNING: DEPRECATED!'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'='\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/bitsandbytes/optim/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# This source code is licensed under the MIT license found in the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# LICENSE file in the root directory of this source tree.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0madam\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdam8bit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdam32bit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0madamw\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdamW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdamW8bit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdamW32bit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msgd\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSGD8bit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSGD32bit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/bitsandbytes/optim/adam.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbitsandbytes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOptimizer2State\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbitsandbytes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/bitsandbytes/optim/optimizer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# LICENSE file in the root directory of this source tree.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mbitsandbytes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/bitsandbytes/functional.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mlib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/libbitsandbytes.so'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mname2qmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ctypes/__init__.py\u001b[0m in \u001b[0;36mLoadLibrary\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dlltype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0m__class_getitem__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenericAlias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: libcudart.so.11.0: cannot open shared object file: No such file or directory"
          ]
        }
      ],
      "source": [
        "import bitsandbytes as bnb\n",
        "import torch\n",
        "\n",
        "print(bnb.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cdb862b",
      "metadata": {
        "id": "0cdb862b"
      },
      "source": [
        "## 4. Load the Pre-Trained Model (LLaMA 1.1B or Similar)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31bcdc99",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "89be465f7d554286a2971cbde1b9f974",
            "15f0831c1ef04d5f8c90bf5dff6e39f1",
            "2bc19ebde3f74a878e50007cca666996",
            "3426207c55274796bb5e6b9efc3c6137",
            "fdfb92db9d4640aa9061a6aace553a8f",
            "153a78332a2643399a81891f823c58fe",
            "01bde8596138444c87bdce71e4c57a20",
            "e11117dcce4b461f9b54b58599b265c7",
            "7d6d758d333c4219aba0502fa87f8406",
            "b15b518475224f9ea3aa2af5bd4a1c9a",
            "ac80da632a11422ba40fa426643145ad"
          ]
        },
        "id": "31bcdc99",
        "outputId": "f4a7e118-bc64-4435-9b20-0ccc9a075bb7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89be465f7d554286a2971cbde1b9f974",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model and tokenizer loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "\n",
        "model_name = \"tiiuae/falcon-7b-instruct\"  # Example of a smaller model for testing\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "quantization_config = BitsAndBytesConfig(load_in_8bit=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=quantization_config,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "print(\"Model and tokenizer loaded successfully.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4Zq-o3IFNbFv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Zq-o3IFNbFv",
        "outputId": "7821b764-49a3-481c-d680-61b4c18cf750"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'text': 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.', 'label': 0}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load a sample dataset from Hugging Face\n",
        "dataset = load_dataset(\"imdb\", split=\"train[:1%]\")\n",
        "print(dataset[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fzyhnNYSQ3ge",
      "metadata": {
        "id": "fzyhnNYSQ3ge"
      },
      "outputs": [],
      "source": [
        "\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff216e83",
      "metadata": {
        "id": "ff216e83"
      },
      "source": [
        "## 5. Tokenization of the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f8c3c91",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f8c3c91",
        "outputId": "ac88bb04-964f-4707-a87b-d814ad99b7a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'text': 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.', 'label': 0, 'input_ids': [52, 28694, 295, 4582, 319, 3106, 42353, 24, 38845, 48954, 427, 491, 2028, 2946, 875, 275, 455, 248, 21681, 325, 12380, 334, 635, 334, 398, 772, 4171, 272, 204, 3954, 34, 25, 295, 614, 3262, 325, 388, 772, 334, 398, 25208, 431, 493, 25, 62, 25, 21359, 565, 334, 1779, 3506, 271, 3464, 414, 2020, 23, 4859, 1003, 241, 4838, 275, 7593, 3558, 204, 13, 3079, 49698, 470, 13, 295, 1037, 618, 271, 760, 414, 312, 2838, 8275, 1162, 204, 5285, 1162, 204, 2541, 487, 8965, 304, 20813, 1111, 241, 2115, 20132, 11125, 3457, 5200, 51037, 569, 4045, 271, 1730, 2096, 674, 418, 544, 1063, 25, 529, 2057, 674, 4045, 271, 1966, 573, 23901, 482, 271, 1591, 596, 3229, 275, 15268, 313, 637, 248, 3608, 3260, 9410, 1465], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(example[\"text\"], padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Use a data collator that handles padding and attention masks\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")\n",
        "\n",
        "print(tokenized_dataset[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db4a9fd1",
      "metadata": {
        "id": "db4a9fd1"
      },
      "source": [
        "## 6. Zero-Shot Inference Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "718450af",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "718450af",
        "outputId": "4e2d3369-d93c-4524-8cc2-b96f94687fec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is the capital of France?\n",
            "The capital of France is Paris.<|endoftext|>\n"
          ]
        }
      ],
      "source": [
        "\n",
        "inputs = tokenizer(\"What is the capital of France?\", return_tensors=\"pt\").to('cuda')\n",
        "outputs = model.generate(inputs['input_ids'], max_length=20)\n",
        "print(tokenizer.decode(outputs[0]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e55930ad",
      "metadata": {
        "id": "e55930ad"
      },
      "source": [
        "## 7. Pre-process the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "906abd50",
      "metadata": {
        "id": "906abd50"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Prepare the dataset for training\n",
        "tokenized_dataset = tokenized_dataset.remove_columns([\"text\"])\n",
        "tokenized_dataset.set_format(\"torch\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9473c314",
      "metadata": {
        "id": "9473c314"
      },
      "source": [
        "## 8. Prepare the Model for QLoRA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c78a0c7a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c78a0c7a",
        "outputId": "6ec29418-d49f-447e-9732-db84de88f25d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient checkpointing enabled. Model is already on the correct device.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Enable gradient checkpointing (no need to move model to 'cuda' manually)\n",
        "model.gradient_checkpointing_enable()\n",
        "\n",
        "# The model is already on the correct device when using 8-bit quantization\n",
        "print(\"Gradient checkpointing enabled. Model is already on the correct device.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d07b7eb",
      "metadata": {
        "id": "2d07b7eb"
      },
      "source": [
        "## 9. Set Up PEFT for Fine-Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c358db7c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c358db7c",
        "outputId": "2bb96cad-588d-448e-bade-77442502d05d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "transformer\n",
            "transformer.word_embeddings\n",
            "transformer.h\n",
            "transformer.h.0\n",
            "transformer.h.0.self_attention\n",
            "transformer.h.0.self_attention.query_key_value\n",
            "transformer.h.0.self_attention.dense\n",
            "transformer.h.0.self_attention.attention_dropout\n",
            "transformer.h.0.self_attention.rotary_emb\n",
            "transformer.h.0.mlp\n",
            "transformer.h.0.mlp.dense_h_to_4h\n",
            "transformer.h.0.mlp.act\n",
            "transformer.h.0.mlp.dense_4h_to_h\n",
            "transformer.h.0.input_layernorm\n",
            "transformer.h.1\n",
            "transformer.h.1.self_attention\n",
            "transformer.h.1.self_attention.query_key_value\n",
            "transformer.h.1.self_attention.dense\n",
            "transformer.h.1.self_attention.attention_dropout\n",
            "transformer.h.1.self_attention.rotary_emb\n",
            "transformer.h.1.mlp\n",
            "transformer.h.1.mlp.dense_h_to_4h\n",
            "transformer.h.1.mlp.act\n",
            "transformer.h.1.mlp.dense_4h_to_h\n",
            "transformer.h.1.input_layernorm\n",
            "transformer.h.2\n",
            "transformer.h.2.self_attention\n",
            "transformer.h.2.self_attention.query_key_value\n",
            "transformer.h.2.self_attention.dense\n",
            "transformer.h.2.self_attention.attention_dropout\n",
            "transformer.h.2.self_attention.rotary_emb\n",
            "transformer.h.2.mlp\n",
            "transformer.h.2.mlp.dense_h_to_4h\n",
            "transformer.h.2.mlp.act\n",
            "transformer.h.2.mlp.dense_4h_to_h\n",
            "transformer.h.2.input_layernorm\n",
            "transformer.h.3\n",
            "transformer.h.3.self_attention\n",
            "transformer.h.3.self_attention.query_key_value\n",
            "transformer.h.3.self_attention.dense\n",
            "transformer.h.3.self_attention.attention_dropout\n",
            "transformer.h.3.self_attention.rotary_emb\n",
            "transformer.h.3.mlp\n",
            "transformer.h.3.mlp.dense_h_to_4h\n",
            "transformer.h.3.mlp.act\n",
            "transformer.h.3.mlp.dense_4h_to_h\n",
            "transformer.h.3.input_layernorm\n",
            "transformer.h.4\n",
            "transformer.h.4.self_attention\n",
            "transformer.h.4.self_attention.query_key_value\n",
            "transformer.h.4.self_attention.dense\n",
            "transformer.h.4.self_attention.attention_dropout\n",
            "transformer.h.4.self_attention.rotary_emb\n",
            "transformer.h.4.mlp\n",
            "transformer.h.4.mlp.dense_h_to_4h\n",
            "transformer.h.4.mlp.act\n",
            "transformer.h.4.mlp.dense_4h_to_h\n",
            "transformer.h.4.input_layernorm\n",
            "transformer.h.5\n",
            "transformer.h.5.self_attention\n",
            "transformer.h.5.self_attention.query_key_value\n",
            "transformer.h.5.self_attention.dense\n",
            "transformer.h.5.self_attention.attention_dropout\n",
            "transformer.h.5.self_attention.rotary_emb\n",
            "transformer.h.5.mlp\n",
            "transformer.h.5.mlp.dense_h_to_4h\n",
            "transformer.h.5.mlp.act\n",
            "transformer.h.5.mlp.dense_4h_to_h\n",
            "transformer.h.5.input_layernorm\n",
            "transformer.h.6\n",
            "transformer.h.6.self_attention\n",
            "transformer.h.6.self_attention.query_key_value\n",
            "transformer.h.6.self_attention.dense\n",
            "transformer.h.6.self_attention.attention_dropout\n",
            "transformer.h.6.self_attention.rotary_emb\n",
            "transformer.h.6.mlp\n",
            "transformer.h.6.mlp.dense_h_to_4h\n",
            "transformer.h.6.mlp.act\n",
            "transformer.h.6.mlp.dense_4h_to_h\n",
            "transformer.h.6.input_layernorm\n",
            "transformer.h.7\n",
            "transformer.h.7.self_attention\n",
            "transformer.h.7.self_attention.query_key_value\n",
            "transformer.h.7.self_attention.dense\n",
            "transformer.h.7.self_attention.attention_dropout\n",
            "transformer.h.7.self_attention.rotary_emb\n",
            "transformer.h.7.mlp\n",
            "transformer.h.7.mlp.dense_h_to_4h\n",
            "transformer.h.7.mlp.act\n",
            "transformer.h.7.mlp.dense_4h_to_h\n",
            "transformer.h.7.input_layernorm\n",
            "transformer.h.8\n",
            "transformer.h.8.self_attention\n",
            "transformer.h.8.self_attention.query_key_value\n",
            "transformer.h.8.self_attention.dense\n",
            "transformer.h.8.self_attention.attention_dropout\n",
            "transformer.h.8.self_attention.rotary_emb\n",
            "transformer.h.8.mlp\n",
            "transformer.h.8.mlp.dense_h_to_4h\n",
            "transformer.h.8.mlp.act\n",
            "transformer.h.8.mlp.dense_4h_to_h\n",
            "transformer.h.8.input_layernorm\n",
            "transformer.h.9\n",
            "transformer.h.9.self_attention\n",
            "transformer.h.9.self_attention.query_key_value\n",
            "transformer.h.9.self_attention.dense\n",
            "transformer.h.9.self_attention.attention_dropout\n",
            "transformer.h.9.self_attention.rotary_emb\n",
            "transformer.h.9.mlp\n",
            "transformer.h.9.mlp.dense_h_to_4h\n",
            "transformer.h.9.mlp.act\n",
            "transformer.h.9.mlp.dense_4h_to_h\n",
            "transformer.h.9.input_layernorm\n",
            "transformer.h.10\n",
            "transformer.h.10.self_attention\n",
            "transformer.h.10.self_attention.query_key_value\n",
            "transformer.h.10.self_attention.dense\n",
            "transformer.h.10.self_attention.attention_dropout\n",
            "transformer.h.10.self_attention.rotary_emb\n",
            "transformer.h.10.mlp\n",
            "transformer.h.10.mlp.dense_h_to_4h\n",
            "transformer.h.10.mlp.act\n",
            "transformer.h.10.mlp.dense_4h_to_h\n",
            "transformer.h.10.input_layernorm\n",
            "transformer.h.11\n",
            "transformer.h.11.self_attention\n",
            "transformer.h.11.self_attention.query_key_value\n",
            "transformer.h.11.self_attention.dense\n",
            "transformer.h.11.self_attention.attention_dropout\n",
            "transformer.h.11.self_attention.rotary_emb\n",
            "transformer.h.11.mlp\n",
            "transformer.h.11.mlp.dense_h_to_4h\n",
            "transformer.h.11.mlp.act\n",
            "transformer.h.11.mlp.dense_4h_to_h\n",
            "transformer.h.11.input_layernorm\n",
            "transformer.h.12\n",
            "transformer.h.12.self_attention\n",
            "transformer.h.12.self_attention.query_key_value\n",
            "transformer.h.12.self_attention.dense\n",
            "transformer.h.12.self_attention.attention_dropout\n",
            "transformer.h.12.self_attention.rotary_emb\n",
            "transformer.h.12.mlp\n",
            "transformer.h.12.mlp.dense_h_to_4h\n",
            "transformer.h.12.mlp.act\n",
            "transformer.h.12.mlp.dense_4h_to_h\n",
            "transformer.h.12.input_layernorm\n",
            "transformer.h.13\n",
            "transformer.h.13.self_attention\n",
            "transformer.h.13.self_attention.query_key_value\n",
            "transformer.h.13.self_attention.dense\n",
            "transformer.h.13.self_attention.attention_dropout\n",
            "transformer.h.13.self_attention.rotary_emb\n",
            "transformer.h.13.mlp\n",
            "transformer.h.13.mlp.dense_h_to_4h\n",
            "transformer.h.13.mlp.act\n",
            "transformer.h.13.mlp.dense_4h_to_h\n",
            "transformer.h.13.input_layernorm\n",
            "transformer.h.14\n",
            "transformer.h.14.self_attention\n",
            "transformer.h.14.self_attention.query_key_value\n",
            "transformer.h.14.self_attention.dense\n",
            "transformer.h.14.self_attention.attention_dropout\n",
            "transformer.h.14.self_attention.rotary_emb\n",
            "transformer.h.14.mlp\n",
            "transformer.h.14.mlp.dense_h_to_4h\n",
            "transformer.h.14.mlp.act\n",
            "transformer.h.14.mlp.dense_4h_to_h\n",
            "transformer.h.14.input_layernorm\n",
            "transformer.h.15\n",
            "transformer.h.15.self_attention\n",
            "transformer.h.15.self_attention.query_key_value\n",
            "transformer.h.15.self_attention.dense\n",
            "transformer.h.15.self_attention.attention_dropout\n",
            "transformer.h.15.self_attention.rotary_emb\n",
            "transformer.h.15.mlp\n",
            "transformer.h.15.mlp.dense_h_to_4h\n",
            "transformer.h.15.mlp.act\n",
            "transformer.h.15.mlp.dense_4h_to_h\n",
            "transformer.h.15.input_layernorm\n",
            "transformer.h.16\n",
            "transformer.h.16.self_attention\n",
            "transformer.h.16.self_attention.query_key_value\n",
            "transformer.h.16.self_attention.dense\n",
            "transformer.h.16.self_attention.attention_dropout\n",
            "transformer.h.16.self_attention.rotary_emb\n",
            "transformer.h.16.mlp\n",
            "transformer.h.16.mlp.dense_h_to_4h\n",
            "transformer.h.16.mlp.act\n",
            "transformer.h.16.mlp.dense_4h_to_h\n",
            "transformer.h.16.input_layernorm\n",
            "transformer.h.17\n",
            "transformer.h.17.self_attention\n",
            "transformer.h.17.self_attention.query_key_value\n",
            "transformer.h.17.self_attention.dense\n",
            "transformer.h.17.self_attention.attention_dropout\n",
            "transformer.h.17.self_attention.rotary_emb\n",
            "transformer.h.17.mlp\n",
            "transformer.h.17.mlp.dense_h_to_4h\n",
            "transformer.h.17.mlp.act\n",
            "transformer.h.17.mlp.dense_4h_to_h\n",
            "transformer.h.17.input_layernorm\n",
            "transformer.h.18\n",
            "transformer.h.18.self_attention\n",
            "transformer.h.18.self_attention.query_key_value\n",
            "transformer.h.18.self_attention.dense\n",
            "transformer.h.18.self_attention.attention_dropout\n",
            "transformer.h.18.self_attention.rotary_emb\n",
            "transformer.h.18.mlp\n",
            "transformer.h.18.mlp.dense_h_to_4h\n",
            "transformer.h.18.mlp.act\n",
            "transformer.h.18.mlp.dense_4h_to_h\n",
            "transformer.h.18.input_layernorm\n",
            "transformer.h.19\n",
            "transformer.h.19.self_attention\n",
            "transformer.h.19.self_attention.query_key_value\n",
            "transformer.h.19.self_attention.dense\n",
            "transformer.h.19.self_attention.attention_dropout\n",
            "transformer.h.19.self_attention.rotary_emb\n",
            "transformer.h.19.mlp\n",
            "transformer.h.19.mlp.dense_h_to_4h\n",
            "transformer.h.19.mlp.act\n",
            "transformer.h.19.mlp.dense_4h_to_h\n",
            "transformer.h.19.input_layernorm\n",
            "transformer.h.20\n",
            "transformer.h.20.self_attention\n",
            "transformer.h.20.self_attention.query_key_value\n",
            "transformer.h.20.self_attention.dense\n",
            "transformer.h.20.self_attention.attention_dropout\n",
            "transformer.h.20.self_attention.rotary_emb\n",
            "transformer.h.20.mlp\n",
            "transformer.h.20.mlp.dense_h_to_4h\n",
            "transformer.h.20.mlp.act\n",
            "transformer.h.20.mlp.dense_4h_to_h\n",
            "transformer.h.20.input_layernorm\n",
            "transformer.h.21\n",
            "transformer.h.21.self_attention\n",
            "transformer.h.21.self_attention.query_key_value\n",
            "transformer.h.21.self_attention.dense\n",
            "transformer.h.21.self_attention.attention_dropout\n",
            "transformer.h.21.self_attention.rotary_emb\n",
            "transformer.h.21.mlp\n",
            "transformer.h.21.mlp.dense_h_to_4h\n",
            "transformer.h.21.mlp.act\n",
            "transformer.h.21.mlp.dense_4h_to_h\n",
            "transformer.h.21.input_layernorm\n",
            "transformer.h.22\n",
            "transformer.h.22.self_attention\n",
            "transformer.h.22.self_attention.query_key_value\n",
            "transformer.h.22.self_attention.dense\n",
            "transformer.h.22.self_attention.attention_dropout\n",
            "transformer.h.22.self_attention.rotary_emb\n",
            "transformer.h.22.mlp\n",
            "transformer.h.22.mlp.dense_h_to_4h\n",
            "transformer.h.22.mlp.act\n",
            "transformer.h.22.mlp.dense_4h_to_h\n",
            "transformer.h.22.input_layernorm\n",
            "transformer.h.23\n",
            "transformer.h.23.self_attention\n",
            "transformer.h.23.self_attention.query_key_value\n",
            "transformer.h.23.self_attention.dense\n",
            "transformer.h.23.self_attention.attention_dropout\n",
            "transformer.h.23.self_attention.rotary_emb\n",
            "transformer.h.23.mlp\n",
            "transformer.h.23.mlp.dense_h_to_4h\n",
            "transformer.h.23.mlp.act\n",
            "transformer.h.23.mlp.dense_4h_to_h\n",
            "transformer.h.23.input_layernorm\n",
            "transformer.h.24\n",
            "transformer.h.24.self_attention\n",
            "transformer.h.24.self_attention.query_key_value\n",
            "transformer.h.24.self_attention.dense\n",
            "transformer.h.24.self_attention.attention_dropout\n",
            "transformer.h.24.self_attention.rotary_emb\n",
            "transformer.h.24.mlp\n",
            "transformer.h.24.mlp.dense_h_to_4h\n",
            "transformer.h.24.mlp.act\n",
            "transformer.h.24.mlp.dense_4h_to_h\n",
            "transformer.h.24.input_layernorm\n",
            "transformer.h.25\n",
            "transformer.h.25.self_attention\n",
            "transformer.h.25.self_attention.query_key_value\n",
            "transformer.h.25.self_attention.dense\n",
            "transformer.h.25.self_attention.attention_dropout\n",
            "transformer.h.25.self_attention.rotary_emb\n",
            "transformer.h.25.mlp\n",
            "transformer.h.25.mlp.dense_h_to_4h\n",
            "transformer.h.25.mlp.act\n",
            "transformer.h.25.mlp.dense_4h_to_h\n",
            "transformer.h.25.input_layernorm\n",
            "transformer.h.26\n",
            "transformer.h.26.self_attention\n",
            "transformer.h.26.self_attention.query_key_value\n",
            "transformer.h.26.self_attention.dense\n",
            "transformer.h.26.self_attention.attention_dropout\n",
            "transformer.h.26.self_attention.rotary_emb\n",
            "transformer.h.26.mlp\n",
            "transformer.h.26.mlp.dense_h_to_4h\n",
            "transformer.h.26.mlp.act\n",
            "transformer.h.26.mlp.dense_4h_to_h\n",
            "transformer.h.26.input_layernorm\n",
            "transformer.h.27\n",
            "transformer.h.27.self_attention\n",
            "transformer.h.27.self_attention.query_key_value\n",
            "transformer.h.27.self_attention.dense\n",
            "transformer.h.27.self_attention.attention_dropout\n",
            "transformer.h.27.self_attention.rotary_emb\n",
            "transformer.h.27.mlp\n",
            "transformer.h.27.mlp.dense_h_to_4h\n",
            "transformer.h.27.mlp.act\n",
            "transformer.h.27.mlp.dense_4h_to_h\n",
            "transformer.h.27.input_layernorm\n",
            "transformer.h.28\n",
            "transformer.h.28.self_attention\n",
            "transformer.h.28.self_attention.query_key_value\n",
            "transformer.h.28.self_attention.dense\n",
            "transformer.h.28.self_attention.attention_dropout\n",
            "transformer.h.28.self_attention.rotary_emb\n",
            "transformer.h.28.mlp\n",
            "transformer.h.28.mlp.dense_h_to_4h\n",
            "transformer.h.28.mlp.act\n",
            "transformer.h.28.mlp.dense_4h_to_h\n",
            "transformer.h.28.input_layernorm\n",
            "transformer.h.29\n",
            "transformer.h.29.self_attention\n",
            "transformer.h.29.self_attention.query_key_value\n",
            "transformer.h.29.self_attention.dense\n",
            "transformer.h.29.self_attention.attention_dropout\n",
            "transformer.h.29.self_attention.rotary_emb\n",
            "transformer.h.29.mlp\n",
            "transformer.h.29.mlp.dense_h_to_4h\n",
            "transformer.h.29.mlp.act\n",
            "transformer.h.29.mlp.dense_4h_to_h\n",
            "transformer.h.29.input_layernorm\n",
            "transformer.h.30\n",
            "transformer.h.30.self_attention\n",
            "transformer.h.30.self_attention.query_key_value\n",
            "transformer.h.30.self_attention.dense\n",
            "transformer.h.30.self_attention.attention_dropout\n",
            "transformer.h.30.self_attention.rotary_emb\n",
            "transformer.h.30.mlp\n",
            "transformer.h.30.mlp.dense_h_to_4h\n",
            "transformer.h.30.mlp.act\n",
            "transformer.h.30.mlp.dense_4h_to_h\n",
            "transformer.h.30.input_layernorm\n",
            "transformer.h.31\n",
            "transformer.h.31.self_attention\n",
            "transformer.h.31.self_attention.query_key_value\n",
            "transformer.h.31.self_attention.dense\n",
            "transformer.h.31.self_attention.attention_dropout\n",
            "transformer.h.31.self_attention.rotary_emb\n",
            "transformer.h.31.mlp\n",
            "transformer.h.31.mlp.dense_h_to_4h\n",
            "transformer.h.31.mlp.act\n",
            "transformer.h.31.mlp.dense_4h_to_h\n",
            "transformer.h.31.input_layernorm\n",
            "transformer.ln_f\n",
            "transformer.rotary_emb\n",
            "lm_head\n"
          ]
        }
      ],
      "source": [
        "for name, module in model.named_modules():\n",
        "    print(name)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jtERBinyRhYf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtERBinyRhYf",
        "outputId": "058cb2ec-1b9a-4606-c15e-25349db806ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PEFT model configured.\n"
          ]
        }
      ],
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "# Update target modules based on model inspection\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"self_attention.query_key_value\"],  # Update with actual module names\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "print(\"PEFT model configured.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EfNcylQBUEg1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfNcylQBUEg1",
        "outputId": "34c1b663-4fd5-45cd-8d23-7ddbddc20299"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['label', 'input_ids', 'attention_mask']\n",
            "{'label': tensor(0), 'input_ids': tensor([   52, 28694,   295,  4582,   319,  3106, 42353,    24, 38845, 48954,\n",
            "          427,   491,  2028,  2946,   875,   275,   455,   248, 21681,   325,\n",
            "        12380,   334,   635,   334,   398,   772,  4171,   272,   204,  3954,\n",
            "           34,    25,   295,   614,  3262,   325,   388,   772,   334,   398,\n",
            "        25208,   431,   493,    25,    62,    25, 21359,   565,   334,  1779,\n",
            "         3506,   271,  3464,   414,  2020,    23,  4859,  1003,   241,  4838,\n",
            "          275,  7593,  3558,   204,    13,  3079, 49698,   470,    13,   295,\n",
            "         1037,   618,   271,   760,   414,   312,  2838,  8275,  1162,   204,\n",
            "         5285,  1162,   204,  2541,   487,  8965,   304, 20813,  1111,   241,\n",
            "         2115, 20132, 11125,  3457,  5200, 51037,   569,  4045,   271,  1730,\n",
            "         2096,   674,   418,   544,  1063,    25,   529,  2057,   674,  4045,\n",
            "          271,  1966,   573, 23901,   482,   271,  1591,   596,  3229,   275,\n",
            "        15268,   313,   637,   248,  3608,  3260,  9410,  1465]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1])}\n"
          ]
        }
      ],
      "source": [
        "print(tokenized_dataset.column_names)\n",
        "print(tokenized_dataset[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WbGepA3cUJyK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590,
          "referenced_widgets": [
            "620165239f124ad3b303df16cf6cecdb",
            "4eb4809d2a67432fae992f52d920a010",
            "6573672c1b7643a0a833fdff5feee0b0",
            "935274cc809c4f50a9cd47ef7b389316",
            "13abb04d9f14401ba4d84feca13cbaba",
            "a915ae45b7b14ea28b326da47668d996",
            "6edc7a85fb7a4a32a53905af132c8484",
            "564991b484af477d8fac78dc0d684a81",
            "11b6f064994b41bcb877ebb4560d443e",
            "4c03bec9a91f421ab797888253c35bad",
            "1aac32a6aa9847259db903621b2ce92a"
          ]
        },
        "id": "WbGepA3cUJyK",
        "outputId": "b8adc8fb-0e92-44b4-d495-3514ef900e7c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "620165239f124ad3b303df16cf6cecdb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'label': tensor(0), 'input_ids': tensor([   52, 28694,   295,  4582,   319,  3106, 42353,    24, 38845, 48954,\n",
            "          427,   491,  2028,  2946,   875,   275,   455,   248, 21681,   325,\n",
            "        12380,   334,   635,   334,   398,   772,  4171,   272,   204,  3954,\n",
            "           34,    25,   295,   614,  3262,   325,   388,   772,   334,   398,\n",
            "        25208,   431,   493,    25,    62,    25, 21359,   565,   334,  1779,\n",
            "         3506,   271,  3464,   414,  2020,    23,  4859,  1003,   241,  4838,\n",
            "          275,  7593,  3558,   204,    13,  3079, 49698,   470,    13,   295,\n",
            "         1037,   618,   271,   760,   414,   312,  2838,  8275,  1162,   204,\n",
            "         5285,  1162,   204,  2541,   487,  8965,   304, 20813,  1111,   241,\n",
            "         2115, 20132, 11125,  3457,  5200, 51037,   569,  4045,   271,  1730,\n",
            "         2096,   674,   418,   544,  1063,    25,   529,  2057,   674,  4045,\n",
            "          271,  1966,   573, 23901,   482,   271,  1591,   596,  3229,   275,\n",
            "        15268,   313,   637,   248,  3608,  3260,  9410,  1465]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor([   52, 28694,   295,  4582,   319,  3106, 42353,    24, 38845, 48954,\n",
            "          427,   491,  2028,  2946,   875,   275,   455,   248, 21681,   325,\n",
            "        12380,   334,   635,   334,   398,   772,  4171,   272,   204,  3954,\n",
            "           34,    25,   295,   614,  3262,   325,   388,   772,   334,   398,\n",
            "        25208,   431,   493,    25,    62,    25, 21359,   565,   334,  1779,\n",
            "         3506,   271,  3464,   414,  2020,    23,  4859,  1003,   241,  4838,\n",
            "          275,  7593,  3558,   204,    13,  3079, 49698,   470,    13,   295,\n",
            "         1037,   618,   271,   760,   414,   312,  2838,  8275,  1162,   204,\n",
            "         5285,  1162,   204,  2541,   487,  8965,   304, 20813,  1111,   241,\n",
            "         2115, 20132, 11125,  3457,  5200, 51037,   569,  4045,   271,  1730,\n",
            "         2096,   674,   418,   544,  1063,    25,   529,  2057,   674,  4045,\n",
            "          271,  1966,   573, 23901,   482,   271,  1591,   596,  3229,   275,\n",
            "        15268,   313,   637,   248,  3608,  3260,  9410,  1465])}\n"
          ]
        }
      ],
      "source": [
        "def preprocess_for_clm(example):\n",
        "    # Ensure input_ids and labels are properly set\n",
        "    example[\"input_ids\"] = example[\"input_ids\"]\n",
        "    example[\"labels\"] = example[\"input_ids\"]\n",
        "    return example\n",
        "\n",
        "# Apply the preprocessing to fix the dataset\n",
        "tokenized_dataset = tokenized_dataset.map(preprocess_for_clm, batched=True)\n",
        "print(tokenized_dataset[0])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "T4EVJWleUnWz",
      "metadata": {
        "id": "T4EVJWleUnWz"
      },
      "outputs": [],
      "source": [
        "model.config.use_cache = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cQ-KwOe3VETF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQ-KwOe3VETF",
        "outputId": "da5bbddc-3dba-4687-f89c-555874f56fb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['label', 'input_ids', 'attention_mask', 'labels']\n",
            "input_ids: tensor([   52, 28694,   295,  4582,   319,  3106, 42353,    24, 38845, 48954,\n",
            "          427,   491,  2028,  2946,   875,   275,   455,   248, 21681,   325,\n",
            "        12380,   334,   635,   334,   398,   772,  4171,   272,   204,  3954,\n",
            "           34,    25,   295,   614,  3262,   325,   388,   772,   334,   398,\n",
            "        25208,   431,   493,    25,    62,    25, 21359,   565,   334,  1779,\n",
            "         3506,   271,  3464,   414,  2020,    23,  4859,  1003,   241,  4838,\n",
            "          275,  7593,  3558,   204,    13,  3079, 49698,   470,    13,   295,\n",
            "         1037,   618,   271,   760,   414,   312,  2838,  8275,  1162,   204,\n",
            "         5285,  1162,   204,  2541,   487,  8965,   304, 20813,  1111,   241,\n",
            "         2115, 20132, 11125,  3457,  5200, 51037,   569,  4045,   271,  1730,\n",
            "         2096,   674,   418,   544,  1063,    25,   529,  2057,   674,  4045,\n",
            "          271,  1966,   573, 23901,   482,   271,  1591,   596,  3229,   275,\n",
            "        15268,   313,   637,   248,  3608,  3260,  9410,  1465])\n",
            "labels: tensor([   52, 28694,   295,  4582,   319,  3106, 42353,    24, 38845, 48954,\n",
            "          427,   491,  2028,  2946,   875,   275,   455,   248, 21681,   325,\n",
            "        12380,   334,   635,   334,   398,   772,  4171,   272,   204,  3954,\n",
            "           34,    25,   295,   614,  3262,   325,   388,   772,   334,   398,\n",
            "        25208,   431,   493,    25,    62,    25, 21359,   565,   334,  1779,\n",
            "         3506,   271,  3464,   414,  2020,    23,  4859,  1003,   241,  4838,\n",
            "          275,  7593,  3558,   204,    13,  3079, 49698,   470,    13,   295,\n",
            "         1037,   618,   271,   760,   414,   312,  2838,  8275,  1162,   204,\n",
            "         5285,  1162,   204,  2541,   487,  8965,   304, 20813,  1111,   241,\n",
            "         2115, 20132, 11125,  3457,  5200, 51037,   569,  4045,   271,  1730,\n",
            "         2096,   674,   418,   544,  1063,    25,   529,  2057,   674,  4045,\n",
            "          271,  1966,   573, 23901,   482,   271,  1591,   596,  3229,   275,\n",
            "        15268,   313,   637,   248,  3608,  3260,  9410,  1465])\n"
          ]
        }
      ],
      "source": [
        "print(tokenized_dataset.column_names)\n",
        "print(\"input_ids:\", tokenized_dataset[0][\"input_ids\"])\n",
        "print(\"labels:\", tokenized_dataset[0][\"labels\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mDl108KfVSvA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDl108KfVSvA",
        "outputId": "60206e32-6899-47dc-f615-636c190e4d8f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PeftModel(\n",
              "  (base_model): LoraModel(\n",
              "    (model): FalconForCausalLM(\n",
              "      (transformer): FalconModel(\n",
              "        (word_embeddings): Embedding(65024, 4544)\n",
              "        (h): ModuleList(\n",
              "          (0-31): 32 x FalconDecoderLayer(\n",
              "            (self_attention): FalconAttention(\n",
              "              (query_key_value): lora.Linear8bitLt(\n",
              "                (base_layer): Linear8bitLt(in_features=4544, out_features=4672, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4544, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=4672, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (dense): Linear8bitLt(in_features=4544, out_features=4544, bias=False)\n",
              "              (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "              (rotary_emb): FalconRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): FalconMLP(\n",
              "              (dense_h_to_4h): Linear8bitLt(in_features=4544, out_features=18176, bias=False)\n",
              "              (act): GELUActivation()\n",
              "              (dense_4h_to_h): Linear8bitLt(in_features=18176, out_features=4544, bias=False)\n",
              "            )\n",
              "            (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (ln_f): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
              "        (rotary_emb): FalconRotaryEmbedding()\n",
              "      )\n",
              "      (lm_head): Linear(in_features=4544, out_features=65024, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BiTrTM3YVXFe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiTrTM3YVXFe",
        "outputId": "419f8ecd-3ea6-4062-ae6d-0d2f08842f34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "base_model.model.transformer.word_embeddings.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.0.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.0.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.0.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.0.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.0.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.0.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.0.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.0.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.1.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.1.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.1.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.1.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.1.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.1.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.1.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.1.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.2.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.2.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.2.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.2.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.2.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.2.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.2.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.2.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.3.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.3.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.3.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.3.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.3.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.3.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.3.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.3.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.4.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.4.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.4.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.4.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.4.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.4.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.4.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.4.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.5.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.5.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.5.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.5.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.5.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.5.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.5.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.5.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.6.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.6.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.6.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.6.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.6.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.6.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.6.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.6.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.7.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.7.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.7.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.7.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.7.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.7.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.7.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.7.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.8.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.8.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.8.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.8.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.8.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.8.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.8.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.8.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.9.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.9.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.9.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.9.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.9.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.9.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.9.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.9.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.10.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.10.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.10.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.10.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.10.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.10.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.10.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.10.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.11.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.11.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.11.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.11.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.11.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.11.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.11.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.11.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.12.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.12.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.12.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.12.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.12.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.12.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.12.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.12.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.13.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.13.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.13.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.13.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.13.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.13.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.13.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.13.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.14.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.14.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.14.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.14.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.14.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.14.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.14.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.14.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.15.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.15.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.15.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.15.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.15.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.15.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.15.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.15.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.16.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.16.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.16.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.16.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.16.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.16.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.16.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.16.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.17.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.17.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.17.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.17.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.17.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.17.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.17.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.17.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.18.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.18.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.18.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.18.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.18.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.18.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.18.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.18.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.19.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.19.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.19.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.19.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.19.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.19.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.19.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.19.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.20.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.20.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.20.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.20.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.20.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.20.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.20.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.20.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.21.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.21.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.21.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.21.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.21.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.21.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.21.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.21.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.22.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.22.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.22.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.22.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.22.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.22.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.22.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.22.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.23.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.23.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.23.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.23.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.23.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.23.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.23.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.23.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.24.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.24.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.24.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.24.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.24.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.24.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.24.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.24.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.25.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.25.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.25.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.25.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.25.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.25.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.25.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.25.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.26.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.26.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.26.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.26.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.26.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.26.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.26.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.26.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.27.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.27.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.27.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.27.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.27.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.27.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.27.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.27.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.28.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.28.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.28.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.28.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.28.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.28.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.28.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.28.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.29.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.29.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.29.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.29.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.29.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.29.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.29.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.29.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.30.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.30.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.30.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.30.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.30.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.30.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.30.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.30.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.31.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.31.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.31.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.transformer.h.31.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.31.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.31.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.transformer.h.31.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.h.31.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.ln_f.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.transformer.ln_f.bias: dtype=torch.float16, requires_grad=False\n"
          ]
        }
      ],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(f\"{name}: dtype={param.dtype}, requires_grad={param.requires_grad}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "w7nRl2R8VlJ9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7nRl2R8VlJ9",
        "outputId": "5346345b-5079-41fb-bdcc-a55633d7f08c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping non-float parameter: base_model.model.transformer.h.0.self_attention.query_key_value.base_layer.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.0.self_attention.dense.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.0.mlp.dense_h_to_4h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.0.mlp.dense_4h_to_h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.1.self_attention.query_key_value.base_layer.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.1.self_attention.dense.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.1.mlp.dense_h_to_4h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.1.mlp.dense_4h_to_h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.2.self_attention.query_key_value.base_layer.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.2.self_attention.dense.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.2.mlp.dense_h_to_4h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.2.mlp.dense_4h_to_h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.3.self_attention.query_key_value.base_layer.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.3.self_attention.dense.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.3.mlp.dense_h_to_4h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.3.mlp.dense_4h_to_h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.4.self_attention.query_key_value.base_layer.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.4.self_attention.dense.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.4.mlp.dense_h_to_4h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.4.mlp.dense_4h_to_h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.5.self_attention.query_key_value.base_layer.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.5.self_attention.dense.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.5.mlp.dense_h_to_4h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.5.mlp.dense_4h_to_h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.6.self_attention.query_key_value.base_layer.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.6.self_attention.dense.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.6.mlp.dense_h_to_4h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.6.mlp.dense_4h_to_h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.7.self_attention.query_key_value.base_layer.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.7.self_attention.dense.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.7.mlp.dense_h_to_4h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.7.mlp.dense_4h_to_h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.8.self_attention.query_key_value.base_layer.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.8.self_attention.dense.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.8.mlp.dense_h_to_4h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.8.mlp.dense_4h_to_h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.9.self_attention.query_key_value.base_layer.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.9.self_attention.dense.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.9.mlp.dense_h_to_4h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.9.mlp.dense_4h_to_h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.10.self_attention.query_key_value.base_layer.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.10.self_attention.dense.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.10.mlp.dense_h_to_4h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.10.mlp.dense_4h_to_h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.11.self_attention.query_key_value.base_layer.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.11.self_attention.dense.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.11.mlp.dense_h_to_4h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.11.mlp.dense_4h_to_h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.12.self_attention.query_key_value.base_layer.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.12.self_attention.dense.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.12.mlp.dense_h_to_4h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.12.mlp.dense_4h_to_h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.13.self_attention.query_key_value.base_layer.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.13.self_attention.dense.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.13.mlp.dense_h_to_4h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.13.mlp.dense_4h_to_h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.14.self_attention.query_key_value.base_layer.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.14.self_attention.dense.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.14.mlp.dense_h_to_4h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.14.mlp.dense_4h_to_h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.15.self_attention.query_key_value.base_layer.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.15.self_attention.dense.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.15.mlp.dense_h_to_4h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.15.mlp.dense_4h_to_h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.16.self_attention.query_key_value.base_layer.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.16.self_attention.dense.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.16.mlp.dense_h_to_4h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.16.mlp.dense_4h_to_h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.17.self_attention.query_key_value.base_layer.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.17.self_attention.dense.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.17.mlp.dense_h_to_4h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.17.mlp.dense_4h_to_h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.18.self_attention.query_key_value.base_layer.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.18.self_attention.dense.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.18.mlp.dense_h_to_4h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.18.mlp.dense_4h_to_h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.19.self_attention.query_key_value.base_layer.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.19.self_attention.dense.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.19.mlp.dense_h_to_4h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.19.mlp.dense_4h_to_h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.20.self_attention.query_key_value.base_layer.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.20.self_attention.dense.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.20.mlp.dense_h_to_4h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.20.mlp.dense_4h_to_h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.21.self_attention.query_key_value.base_layer.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.21.self_attention.dense.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.21.mlp.dense_h_to_4h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.21.mlp.dense_4h_to_h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.22.self_attention.query_key_value.base_layer.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.22.self_attention.dense.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.22.mlp.dense_h_to_4h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.22.mlp.dense_4h_to_h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.23.self_attention.query_key_value.base_layer.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.23.self_attention.dense.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.23.mlp.dense_h_to_4h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.23.mlp.dense_4h_to_h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.24.self_attention.query_key_value.base_layer.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.24.self_attention.dense.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.24.mlp.dense_h_to_4h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.24.mlp.dense_4h_to_h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.25.self_attention.query_key_value.base_layer.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.25.self_attention.dense.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.25.mlp.dense_h_to_4h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.25.mlp.dense_4h_to_h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.26.self_attention.query_key_value.base_layer.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.26.self_attention.dense.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.26.mlp.dense_h_to_4h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.26.mlp.dense_4h_to_h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.27.self_attention.query_key_value.base_layer.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.27.self_attention.dense.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.27.mlp.dense_h_to_4h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.27.mlp.dense_4h_to_h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.28.self_attention.query_key_value.base_layer.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.28.self_attention.dense.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.28.mlp.dense_h_to_4h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.28.mlp.dense_4h_to_h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.29.self_attention.query_key_value.base_layer.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.29.self_attention.dense.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.29.mlp.dense_h_to_4h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.29.mlp.dense_4h_to_h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.30.self_attention.query_key_value.base_layer.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.30.self_attention.dense.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.30.mlp.dense_h_to_4h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.30.mlp.dense_4h_to_h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.31.self_attention.query_key_value.base_layer.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.31.self_attention.dense.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.31.mlp.dense_h_to_4h.weight with dtype torch.int8\n",
            "Skipping non-float parameter: base_model.model.transformer.h.31.mlp.dense_4h_to_h.weight with dtype torch.int8\n"
          ]
        }
      ],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if param.dtype in [torch.float16, torch.float32, torch.bfloat16]:  # Only apply to floating-point tensors\n",
        "        param.requires_grad = True\n",
        "    else:\n",
        "        print(f\"Skipping non-float parameter: {name} with dtype {param.dtype}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hkEimE9iWKj1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkEimE9iWKj1",
        "outputId": "c15e7c3e-8e71-47cd-bf1e-905bd3fb17af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_ids: tensor([   52, 28694,   295,  4582,   319,  3106, 42353,    24, 38845, 48954,\n",
            "          427,   491,  2028,  2946,   875,   275,   455,   248, 21681,   325,\n",
            "        12380,   334,   635,   334,   398,   772,  4171,   272,   204,  3954,\n",
            "           34,    25,   295,   614,  3262,   325,   388,   772,   334,   398,\n",
            "        25208,   431,   493,    25,    62,    25, 21359,   565,   334,  1779,\n",
            "         3506,   271,  3464,   414,  2020,    23,  4859,  1003,   241,  4838,\n",
            "          275,  7593,  3558,   204,    13,  3079, 49698,   470,    13,   295,\n",
            "         1037,   618,   271,   760,   414,   312,  2838,  8275,  1162,   204,\n",
            "         5285,  1162,   204,  2541,   487,  8965,   304, 20813,  1111,   241,\n",
            "         2115, 20132, 11125,  3457,  5200, 51037,   569,  4045,   271,  1730,\n",
            "         2096,   674,   418,   544,  1063,    25,   529,  2057,   674,  4045,\n",
            "          271,  1966,   573, 23901,   482,   271,  1591,   596,  3229,   275,\n",
            "        15268,   313,   637,   248,  3608,  3260,  9410,  1465])\n",
            "labels: tensor([   52, 28694,   295,  4582,   319,  3106, 42353,    24, 38845, 48954,\n",
            "          427,   491,  2028,  2946,   875,   275,   455,   248, 21681,   325,\n",
            "        12380,   334,   635,   334,   398,   772,  4171,   272,   204,  3954,\n",
            "           34,    25,   295,   614,  3262,   325,   388,   772,   334,   398,\n",
            "        25208,   431,   493,    25,    62,    25, 21359,   565,   334,  1779,\n",
            "         3506,   271,  3464,   414,  2020,    23,  4859,  1003,   241,  4838,\n",
            "          275,  7593,  3558,   204,    13,  3079, 49698,   470,    13,   295,\n",
            "         1037,   618,   271,   760,   414,   312,  2838,  8275,  1162,   204,\n",
            "         5285,  1162,   204,  2541,   487,  8965,   304, 20813,  1111,   241,\n",
            "         2115, 20132, 11125,  3457,  5200, 51037,   569,  4045,   271,  1730,\n",
            "         2096,   674,   418,   544,  1063,    25,   529,  2057,   674,  4045,\n",
            "          271,  1966,   573, 23901,   482,   271,  1591,   596,  3229,   275,\n",
            "        15268,   313,   637,   248,  3608,  3260,  9410,  1465])\n"
          ]
        }
      ],
      "source": [
        "sample = next(iter(tokenized_dataset))\n",
        "print(\"input_ids:\", sample[\"input_ids\"])\n",
        "print(\"labels:\", sample[\"labels\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zZxbXRtbVnqI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZxbXRtbVnqI",
        "outputId": "c8bb5740-a8d2-427d-c204-46c3401b00dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "base_model.model.base_model.model.transformer.word_embeddings.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.0.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.0.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.0.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.0.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.0.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.0.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.0.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.0.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.1.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.1.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.1.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.1.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.1.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.1.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.1.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.1.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.2.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.2.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.2.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.2.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.2.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.2.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.2.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.2.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.3.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.3.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.3.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.3.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.3.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.3.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.3.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.3.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.4.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.4.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.4.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.4.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.4.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.4.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.4.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.4.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.5.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.5.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.5.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.5.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.5.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.5.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.5.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.5.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.6.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.6.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.6.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.6.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.6.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.6.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.6.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.6.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.7.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.7.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.7.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.7.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.7.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.7.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.7.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.7.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.8.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.8.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.8.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.8.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.8.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.8.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.8.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.8.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.9.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.9.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.9.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.9.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.9.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.9.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.9.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.9.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.10.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.10.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.10.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.10.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.10.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.10.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.10.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.10.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.11.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.11.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.11.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.11.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.11.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.11.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.11.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.11.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.12.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.12.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.12.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.12.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.12.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.12.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.12.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.12.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.13.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.13.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.13.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.13.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.13.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.13.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.13.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.13.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.14.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.14.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.14.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.14.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.14.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.14.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.14.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.14.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.15.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.15.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.15.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.15.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.15.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.15.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.15.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.15.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.16.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.16.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.16.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.16.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.16.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.16.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.16.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.16.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.17.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.17.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.17.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.17.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.17.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.17.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.17.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.17.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.18.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.18.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.18.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.18.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.18.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.18.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.18.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.18.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.19.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.19.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.19.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.19.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.19.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.19.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.19.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.19.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.20.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.20.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.20.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.20.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.20.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.20.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.20.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.20.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.21.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.21.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.21.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.21.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.21.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.21.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.21.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.21.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.22.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.22.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.22.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.22.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.22.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.22.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.22.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.22.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.23.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.23.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.23.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.23.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.23.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.23.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.23.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.23.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.24.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.24.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.24.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.24.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.24.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.24.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.24.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.24.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.25.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.25.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.25.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.25.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.25.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.25.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.25.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.25.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.26.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.26.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.26.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.26.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.26.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.26.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.26.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.26.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.27.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.27.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.27.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.27.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.27.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.27.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.27.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.27.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.28.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.28.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.28.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.28.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.28.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.28.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.28.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.28.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.29.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.29.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.29.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.29.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.29.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.29.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.29.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.29.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.30.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.30.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.30.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.30.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.30.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.30.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.30.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.30.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.31.self_attention.query_key_value.base_layer.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.31.self_attention.query_key_value.lora_A.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.31.self_attention.query_key_value.lora_B.default.weight: dtype=torch.float32, requires_grad=True\n",
            "base_model.model.base_model.model.transformer.h.31.self_attention.dense.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.31.mlp.dense_h_to_4h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.31.mlp.dense_4h_to_h.weight: dtype=torch.int8, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.31.input_layernorm.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.h.31.input_layernorm.bias: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.ln_f.weight: dtype=torch.float16, requires_grad=False\n",
            "base_model.model.base_model.model.transformer.ln_f.bias: dtype=torch.float16, requires_grad=False\n"
          ]
        }
      ],
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"self_attention.query_key_value\"],  # Use valid module names from the model\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.train()\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"{name}: dtype={param.dtype}, requires_grad={param.requires_grad}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hWVw32F3VxOP",
      "metadata": {
        "id": "hWVw32F3VxOP"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "# Create a data collator for causal language modeling\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False  # Set mlm (masked language modeling) to False for causal LM\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jUlM8FqUWnV7",
      "metadata": {
        "id": "jUlM8FqUWnV7"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False  # For causal language modeling\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KnAxEwrfWqfV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "KnAxEwrfWqfV",
        "outputId": "d7defaca-172f-412f-f0e5-fab3de5d2b1f"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided ['label']",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-f46bd38ae473>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2169\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2170\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2171\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2172\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2173\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2478\u001b[0m                 \u001b[0mupdate_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2479\u001b[0m                 \u001b[0mnum_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mupdate_step\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_updates\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mremainder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2480\u001b[0;31m                 \u001b[0mbatch_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2481\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2482\u001b[0m                     \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mget_batch_samples\u001b[0;34m(self, epoch_iterator, num_batches)\u001b[0m\n\u001b[1;32m   5151\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5152\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5153\u001b[0;31m                 \u001b[0mbatch_samples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5154\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5155\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/data_loader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;31m# We iterate one batch ahead to check when we are at the end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0mcurrent_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, features, return_tensors)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mreturn_tensors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mreturn_tensors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"np\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36mtorch_call\u001b[0;34m(self, examples)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;31m# Handle dict or lists with proper padding and conversion to tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m             batch = pad_without_fast_tokenizer_warning(\n\u001b[0m\u001b[1;32m    811\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_to_multiple_of\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_to_multiple_of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36mpad_without_fast_tokenizer_warning\u001b[0;34m(tokenizer, *pad_args, **pad_kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mpadded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpad_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpad_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# Restore the state of the warning.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, padding_side, return_attention_mask, return_tensors, verbose)\u001b[0m\n\u001b[1;32m   3303\u001b[0m         \u001b[0;31m# The model's main input name, usually `input_ids`, has been passed for padding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3304\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_input_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mencoded_inputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3305\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   3306\u001b[0m                 \u001b[0;34m\"You should supply an encoding or a list of encodings to this method \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m                 \u001b[0;34mf\"that includes {self.model_input_names[0]}, but you provided {list(encoded_inputs.keys())}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided ['label']"
          ]
        }
      ],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "model.config.use_cache = False\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    max_steps=500,\n",
        "    logging_steps=50,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=50,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    save_steps=100,\n",
        "    save_total_limit=2\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    eval_dataset=tokenized_dataset,\n",
        "    data_collator=data_collator,  # Use the custom data collator\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pXG4Lm4cV_v9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "pXG4Lm4cV_v9",
        "outputId": "1b443bf7-3c3d-4c64-e05f-e32189e8905a"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided ['label']",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-f46bd38ae473>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2169\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2170\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2171\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2172\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2173\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2478\u001b[0m                 \u001b[0mupdate_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2479\u001b[0m                 \u001b[0mnum_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mupdate_step\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_updates\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mremainder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2480\u001b[0;31m                 \u001b[0mbatch_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2481\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2482\u001b[0m                     \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mget_batch_samples\u001b[0;34m(self, epoch_iterator, num_batches)\u001b[0m\n\u001b[1;32m   5151\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5152\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5153\u001b[0;31m                 \u001b[0mbatch_samples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5154\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5155\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/data_loader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;31m# We iterate one batch ahead to check when we are at the end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0mcurrent_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, features, return_tensors)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mreturn_tensors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mreturn_tensors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"np\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36mtorch_call\u001b[0;34m(self, examples)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;31m# Handle dict or lists with proper padding and conversion to tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m             batch = pad_without_fast_tokenizer_warning(\n\u001b[0m\u001b[1;32m    811\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_to_multiple_of\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_to_multiple_of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36mpad_without_fast_tokenizer_warning\u001b[0;34m(tokenizer, *pad_args, **pad_kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mpadded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpad_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpad_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# Restore the state of the warning.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, padding_side, return_attention_mask, return_tensors, verbose)\u001b[0m\n\u001b[1;32m   3303\u001b[0m         \u001b[0;31m# The model's main input name, usually `input_ids`, has been passed for padding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3304\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_input_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mencoded_inputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3305\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   3306\u001b[0m                 \u001b[0;34m\"You should supply an encoding or a list of encodings to this method \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m                 \u001b[0;34mf\"that includes {self.model_input_names[0]}, but you provided {list(encoded_inputs.keys())}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided ['label']"
          ]
        }
      ],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "model.config.use_cache = False\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    max_steps=500,\n",
        "    logging_steps=50,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=50,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    save_steps=100,\n",
        "    save_total_limit=2\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    eval_dataset=tokenized_dataset,\n",
        "    data_collator=data_collator,  # Use the custom data collator\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5df25a32",
      "metadata": {
        "id": "5df25a32"
      },
      "source": [
        "## 10. Train PEFT Adapter"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2384f11",
      "metadata": {
        "id": "f2384f11"
      },
      "source": [
        "## 11. Qualitative Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54ad3d81",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54ad3d81",
        "outputId": "40b3b466-c5b4-4b3e-df2d-9e42920a8848"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Explain the theory of relativity.\n",
            "The theory of relativity, proposed by Albert Einstein, consists of two separate theories: the special theory of relativity and the general theory of relativity. The special theory of relativity, introduced in \n"
          ]
        }
      ],
      "source": [
        "\n",
        "inputs = tokenizer(\"Explain the theory of relativity.\", return_tensors=\"pt\").to('cuda')\n",
        "outputs = model.generate(inputs['input_ids'], max_length=50)\n",
        "print(tokenizer.decode(outputs[0]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18321671",
      "metadata": {
        "id": "18321671"
      },
      "source": [
        "## 12. Quantitative Evaluation using ROUGE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f178c94e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "f178c94e",
        "outputId": "2a62255d-0eca-4c06-921f-6b7ba9fc8b02"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          },
          "evalue": "cannot import name 'load_metric' from 'datasets' (/usr/local/lib/python3.11/dist-packages/datasets/__init__.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-cacefe355e6f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrouge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rouge\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"This is the predicted text.\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mreferences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"This is the reference text.\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'load_metric' from 'datasets' (/usr/local/lib/python3.11/dist-packages/datasets/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from datasets import load_metric\n",
        "\n",
        "rouge = load_metric(\"rouge\")\n",
        "predictions = [\"This is the predicted text.\"]\n",
        "references = [\"This is the reference text.\"]\n",
        "results = rouge.compute(predictions=predictions, references=references)\n",
        "print(results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0901409",
      "metadata": {
        "id": "c0901409"
      },
      "source": [
        "## 13. Save and Upload the Model to Hugging Face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dc7a8ee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "6dc7a8ee",
        "outputId": "f621e9f1-3478-43ba-90a2-bee02fe661ad"
      },
      "outputs": [
        {
          "ename": "HfHubHTTPError",
          "evalue": "401 Client Error: Unauthorized for url: https://huggingface.co/api/repos/create (Request ID: Root=1-67b598f2-6f7e05e83cf027bb22ffa38f;8bb75579-8471-4cfe-9b38-d427c36a08bd)\n\nInvalid username or password.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/api/repos/create",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-a5c30dde0d37>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush_to_hub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"your-huggingface-username/your-model-name\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mpush_to_hub\u001b[0;34m(self, repo_id, use_temp_dir, commit_message, private, token, max_shard_size, create_pr, safe_serialization, revision, commit_description, tags, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0morganization\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeprecated_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"organization\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m         repo_id = self._create_repo(\n\u001b[0m\u001b[1;32m    934\u001b[0m             \u001b[0mrepo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprivate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprivate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepo_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morganization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morganization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36m_create_repo\u001b[0;34m(self, repo_id, private, token, repo_url, organization)\u001b[0m\n\u001b[1;32m    738\u001b[0m                 \u001b[0mrepo_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{organization}/{repo_id}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_repo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprivate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprivate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hf_api.py\u001b[0m in \u001b[0;36mcreate_repo\u001b[0;34m(self, repo_id, token, private, repo_type, exist_ok, resource_group_id, space_sdk, space_hardware, space_storage, space_sleep_time, space_secrets, space_variables)\u001b[0m\n\u001b[1;32m   3479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3480\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3481\u001b[0;31m             \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3482\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3483\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mexist_ok\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m409\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;31m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;31m# as well (request id and/or server error message)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHfHubHTTPError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHfHubHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/api/repos/create (Request ID: Root=1-67b598f2-6f7e05e83cf027bb22ffa38f;8bb75579-8471-4cfe-9b38-d427c36a08bd)\n\nInvalid username or password."
          ]
        }
      ],
      "source": [
        "\n",
        "model.push_to_hub(\"your-huggingface-username/your-model-name\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53d214f0",
      "metadata": {
        "id": "53d214f0"
      },
      "source": [
        "## 14. Capture and Document Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc148797",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc148797",
        "outputId": "9c919b37-cd93-4037-b44a-f94f3f73f0ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Assignment completed!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Add screenshots and outputs as needed to your notebook before submission.\n",
        "print(\"Assignment completed!\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01bde8596138444c87bdce71e4c57a20": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11b6f064994b41bcb877ebb4560d443e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "13abb04d9f14401ba4d84feca13cbaba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "153a78332a2643399a81891f823c58fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15f0831c1ef04d5f8c90bf5dff6e39f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_153a78332a2643399a81891f823c58fe",
            "placeholder": "​",
            "style": "IPY_MODEL_01bde8596138444c87bdce71e4c57a20",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "1aac32a6aa9847259db903621b2ce92a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2bc19ebde3f74a878e50007cca666996": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e11117dcce4b461f9b54b58599b265c7",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d6d758d333c4219aba0502fa87f8406",
            "value": 2
          }
        },
        "3426207c55274796bb5e6b9efc3c6137": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b15b518475224f9ea3aa2af5bd4a1c9a",
            "placeholder": "​",
            "style": "IPY_MODEL_ac80da632a11422ba40fa426643145ad",
            "value": " 2/2 [01:23&lt;00:00, 38.25s/it]"
          }
        },
        "4c03bec9a91f421ab797888253c35bad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4eb4809d2a67432fae992f52d920a010": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a915ae45b7b14ea28b326da47668d996",
            "placeholder": "​",
            "style": "IPY_MODEL_6edc7a85fb7a4a32a53905af132c8484",
            "value": "Map: 100%"
          }
        },
        "564991b484af477d8fac78dc0d684a81": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "620165239f124ad3b303df16cf6cecdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4eb4809d2a67432fae992f52d920a010",
              "IPY_MODEL_6573672c1b7643a0a833fdff5feee0b0",
              "IPY_MODEL_935274cc809c4f50a9cd47ef7b389316"
            ],
            "layout": "IPY_MODEL_13abb04d9f14401ba4d84feca13cbaba"
          }
        },
        "6573672c1b7643a0a833fdff5feee0b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_564991b484af477d8fac78dc0d684a81",
            "max": 250,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11b6f064994b41bcb877ebb4560d443e",
            "value": 250
          }
        },
        "6edc7a85fb7a4a32a53905af132c8484": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d6d758d333c4219aba0502fa87f8406": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89be465f7d554286a2971cbde1b9f974": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15f0831c1ef04d5f8c90bf5dff6e39f1",
              "IPY_MODEL_2bc19ebde3f74a878e50007cca666996",
              "IPY_MODEL_3426207c55274796bb5e6b9efc3c6137"
            ],
            "layout": "IPY_MODEL_fdfb92db9d4640aa9061a6aace553a8f"
          }
        },
        "935274cc809c4f50a9cd47ef7b389316": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c03bec9a91f421ab797888253c35bad",
            "placeholder": "​",
            "style": "IPY_MODEL_1aac32a6aa9847259db903621b2ce92a",
            "value": " 250/250 [00:00&lt;00:00, 6233.69 examples/s]"
          }
        },
        "a915ae45b7b14ea28b326da47668d996": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac80da632a11422ba40fa426643145ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b15b518475224f9ea3aa2af5bd4a1c9a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e11117dcce4b461f9b54b58599b265c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdfb92db9d4640aa9061a6aace553a8f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}